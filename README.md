# ğŸ“¡ Telegram Crawler

A modular, reliable, and resumable Telegram crawler for fetching channel posts, reactions, and threaded comments based on keyword and date range filters.

---

## ğŸš€ Features

- ğŸ” Search by keyword in a public channel
- ğŸ“… Filter posts by Jalali (Shamsi) date range
- ğŸ’¬ Fetch comments on posts (if discussion group is linked)
- â¤ï¸ Extract reactions (emoji counts)
- ğŸ§  Saves progress and resumes after crash or stop
- ğŸ—ƒï¸ Structured file saving (JSON format)
- ğŸ§¯ Handles Telegram rate limits (`FloodWaitError`)
- ğŸ§¼ Clean, modular codebase for maintenance and extension

---

## ğŸ§± Project Structure

```
telegram-crawler/
â”œâ”€â”€ main.py                   # Entry point
â”œâ”€â”€ config.py                 # Your API credentials + target channel
â”œâ”€â”€ fetch/
â”‚   â”œâ”€â”€ posts.py              # Crawls posts with filtering
â”‚   â””â”€â”€ comments.py           # Fetches replies to a post
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ file_manager.py       # Save/load JSON files & crawler state
â”‚   â””â”€â”€ date_converter.py     # Convert Jalali to Gregorian
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ posts/                # Saved posts in JSON (post_id.json)
â”‚   â””â”€â”€ comments/             # Saved comments (post_id.json)
â”œâ”€â”€ session/                  # Telethon session files (auto-generated)
â”œâ”€â”€ state.json                # Stores last post ID crawled per channel
â””â”€â”€ README.md                 # Documentation
```

---

## âš™ï¸ Setup

### 1. Clone the repo

```bash
git clone https://github.com/parvvaresh/telegram-crawler.git
cd telegram-crawler
```

### 2. Install dependencies

```bash
pip install -r requirements.txt
```

> If `requirements.txt` is missing, run:
```bash
pip install telethon jdatetime
```

---

## ğŸ” Configuration

### `config.py`

Edit this file with your Telegram API credentials and target channel:

```python
api_id = 123456               # From my.telegram.org
api_hash = 'your_api_hash'
channel = 'https://t.me/target_channel'
```

---

## ğŸš¦ Usage

Run the crawler:

```bash
python main.py
```

This will:

1. Convert Jalali dates to Gregorian.
2. Search messages by keywords.
3. Filter by date range.
4. Save post info + reactions to `data/posts/`.
5. Save replies/comments to `data/comments/`.

---

## âœ‹ Graceful Stop

To safely stop the crawler:

- Press `CTRL+C`
- It will finish the current operation and exit.
- It resumes later from the last saved message.

---

## ğŸ’¾ Output Format

### Post JSON (data/posts/{post_id}.json)

```json
{
  "post_id": 123456,
  "date": "2025-04-01T12:34:56",
  "author": 987654321,
  "text": "Example content",
  "reactions": [
    {"emoji": "ğŸ”¥", "count": 15},
    {"emoji": "â¤ï¸", "count": 10}
  ]
}
```

### Comments JSON (data/comments/{post_id}.json)

```json
[
  {
    "message_id": 78910,
    "from": 456789123,
    "date": "2025-04-01T13:00:00",
    "text": "This is a reply",
    "reactions": []
  },
  ...
]
```

---

## ğŸ“Œ Notes

- âœ… This only works with **public channels** (or ones you have access to).
- âŒ Cannot fetch data anonymously (API credentials are required).
- âš ï¸ Avoid excessive crawling to prevent rate-limiting (`FloodWaitError`).

---

## ğŸ“œ License

MIT â€” feel free to use, modify, or contribute.

---

## ğŸ¤ Contributing

Pull requests are welcome! For major changes, open an issue first to discuss what youâ€™d like to change.

